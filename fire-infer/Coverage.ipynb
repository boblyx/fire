{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76bc9da-fb5e-4637-8abe-f7d38df675bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Coverage inference\n",
    "\n",
    "# Input layers\n",
    "- Up to 5x 2D coordinates\n",
    "- Up to 64x 2D room vertices\n",
    "- Distance from \n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Union\n",
    "\n",
    "# Adapted from https://www.kaggle.com/code/sheikhartin/logic-gates-in-pytorch\n",
    "# User Logistic Regression because output is either True (comply) or False (not comply)\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Feeds the data to the neural network.\"\"\"\n",
    "        output = torch.sigmoid(self.linear1(x))\n",
    "        output = torch.sigmoid(self.linear2(x))\n",
    "        output = torch.sigmoid(self.linear3(output))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4157637-b67d-4839-abcf-a54ca5523a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: Union[nn.Module, nn.Sequential], criterion: Union[nn.MSELoss, nn.BCELoss],\n",
    "          optimizer: Union[torch.optim.SGD, torch.optim.Adam],\n",
    "          dataset, epochs: int) -> None:          \n",
    "          #X: torch.Tensor, y: torch.Tensor, epochs: int) -> None:\n",
    "    \"\"\"Trains the neural network and reports.\"\"\"\n",
    "    epochs_size = len(str(epochs))  # To beautify when reporting\n",
    "    \n",
    "    for epoch in range(epochs+1):\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Print the loss in every 5% of epochs\n",
    "        if epoch % int(epochs * 0.05) == 0:\n",
    "            print(f'[EPOCH {epoch: >{epochs_size}}/{epochs}] The loss is {loss.item():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ffa3ab1a-ec76-4cd1-bf43-5f4c816174f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load & Preprocess training data\n",
    "\"\"\"\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = '../fire-synth/dataset/1711285332_0f8ffdf0-5625-4ed6-bb82-89bbf7282225.json'\n",
    "df = pd.read_json(file_path)\n",
    "df = pd.json_normalize(df['data'])\n",
    "#print(df.head())\n",
    "len(df.iat[1,1])\n",
    "len(df.iat[2,1])\n",
    "# May need to reindex rooms verts and extinguishers\n",
    "# Until they reach 32 length for verts and 4 length for extinguishers\n",
    "rooms = df[\"room\"]\n",
    "extinguishers = df[\"extinguishers\"]\n",
    "#print(rooms[5000])\n",
    "\n",
    "def hasNegative(vlist):\n",
    "    \"\"\"\n",
    "    Checks if the vertex list has a negative number\n",
    "    \"\"\"\n",
    "    for v in vlist:\n",
    "        for vc in v:\n",
    "            if vc < 0: return True\n",
    "    return False\n",
    "\n",
    "def padVerts(vlist, num = 36):\n",
    "    \"\"\"\n",
    "    Pads vertices so they're all the same length.\n",
    "    TODO: use numpy.pad\n",
    "    \"\"\"\n",
    "    while len(vlist) < num: vlist.append([-1,-1])\n",
    "    return vlist\n",
    "\n",
    "def padVertList(df, column, length = 36):\n",
    "    \"\"\"\n",
    "    Pads a particular column containing list of 2D points with [-1,-1]\n",
    "    to indicate that the points are not used.\n",
    "    \"\"\"\n",
    "    #print(length)\n",
    "    df[column] = df[column].map(lambda x: padVerts(x, length))\n",
    "    return df\n",
    "\n",
    "# STEP 1: TRANSFORM ROOM VERTICES\n",
    "## Double check if its negative\n",
    "#rds = rooms.apply(lambda x: hasNegative(x))\n",
    "#rdf = rds.to_frame()\n",
    "#rdf.query(\"@rdf['room'] == True\")\n",
    "\n",
    "# If all are non-negative, we can use negative vertices to determine non-existent points.\n",
    "df = padVertList(df, \"room\", 36)\n",
    "\n",
    "# Double check if they're all properly padded\n",
    "#rds = df[\"rooms\"].apply(lambda x: len(x))\n",
    "#print(df.iat[0,1])\n",
    "\n",
    "# STEP 2: TRANSFORM EXTINGUISHER POINTS\n",
    "df = padVertList(df, \"extinguishers\", 12)\n",
    "#print(df[\"extinguishers\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f2854e5c-cb9c-4cd9-a192-0c04cdcf8d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.70225e+03 -1.00000e+00 -1.00000e+00 -1.00000e+00 -1.00000e+00\n",
      "  -1.00000e+00 -1.00000e+00 -1.00000e+00 -1.00000e+00 -1.00000e+00\n",
      "  -1.00000e+00 -1.00000e+00]\n",
      " [ 6.55200e+03 -1.00000e+00 -1.00000e+00 -1.00000e+00 -1.00000e+00\n",
      "  -1.00000e+00 -1.00000e+00 -1.00000e+00 -1.00000e+00 -1.00000e+00\n",
      "  -1.00000e+00 -1.00000e+00]]\n",
      "[[    0  9357  9357  6738  6738 11655 11655  3369  3369     0    -1    -1\n",
      "     -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "     -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1]\n",
      " [    0     0  6552  6552  6892  6892 12592 12592  6892  6892    -1    -1\n",
      "     -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
      "     -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1    -1]]\n"
     ]
    }
   ],
   "source": [
    "# Get as numpy arrays\n",
    "ex_np = df[\"extinguishers\"].to_numpy()\n",
    "rm_np = df[\"room\"].to_numpy()\n",
    "\n",
    "# TODO: Transpose vertices such that: \n",
    "# [[x1, y1], [x2, y2] ... [xn, yn]] => [[x1, x2, x3... xn], [y1, y2, y3... ,yn]]\n",
    "ex_all = list()\n",
    "for p in ex_np:\n",
    "    ex_all.append(np.transpose(p))\n",
    "\n",
    "rm_all = list()\n",
    "for rm in rm_np:\n",
    "    rm_all.append(np.transpose(rm))\n",
    "\n",
    "print(ex_all[0])\n",
    "print(rm_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3057255d-89de-4537-92ea-6dc1d0a0b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack data to be put into training cycle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19735dda-51a4-4780-93a7-c2db4e044295",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "input_dim = 2\n",
    "hidden_dim = 3\n",
    "output_dim = 1\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c322e255-74e9-47ab-82cc-bc1418a82baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coverage = LogisticRegression(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model_coverage.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c7e03-4bdc-41a1-8af5-67ecf2def0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model_coverage, criterion, optimizer, dataset, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
